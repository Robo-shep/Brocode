# üîç Project Crux: Market Research Bot

<div align="center">
  
  ![Version](https://img.shields.io/badge/version-1.0.0-blue.svg?cacheSeconds=2592000)
  ![License](https://img.shields.io/badge/License-MIT-yellow.svg)
  ![Python](https://img.shields.io/badge/Python-3.8+-green.svg)
  
</div>

> üß† A lightweight, real-time market intelligence tool that pulls sentiment and discussion insights from Reddit, Hacker News, and Quora ‚Äî tailored specifically for developers, indie hackers, and early-stage product teams.

## ‚ú® What It Does

- üîé **Search & Discover** - Let users search for a product or topic across multiple platforms
- üìä **Aggregate & Analyze** - Collect forum discussions and perform sentiment analysis
- üìà **Visualize & Summarize** - Display consumer sentiment with intuitive visualizations
- üí° **Generate Insights** - Provide AI-generated summaries of trends and discussions

## üåü Why It's Unique

- üë®‚Äçüíª **Developer-Focused** - Built for product builders, not marketing teams
- üîÑ **Multi-Platform** - Combines data from Reddit, Hacker News, and Quora
- üì± **Modular UI** - Real-time sentiment bar, summary, and graphs in a clean interface
- üåâ **Fills the Gap** - Between enterprise tools and basic Reddit searchers

## üõ†Ô∏è Tech Stack

- **üêç Backend**: Python, Flask
- **üï∏Ô∏è Web Scraping**: BeautifulSoup, PRAW (Reddit API)
- **üß† NLP**: spaCy, NLTK
- **üòä Sentiment Analysis**: VADER
- **üñ•Ô∏è Frontend**: HTML, CSS, JavaScript

## üöÄ Getting Started

### Prerequisites

- Python 3.8 or higher
- Internet connection for API access

### 1Ô∏è‚É£ Installation

Download the project files to your local machine or clone the repository:

```bash
git clone https://github.com/Robo-shep/Brocode.git
cd Brocode
```

### 2Ô∏è‚É£ Environment Setup

```bash
# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate  # On Windows
# On macOS/Linux: source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3Ô∏è‚É£ API Configuration

Edit the following files to add your API credentials:

- `src/scrapers/reddit_scraper.py`: Add your Reddit API credentials

```python
REDDIT_CLIENT_ID = "your_client_id"
REDDIT_CLIENT_SECRET = "your_client_secret"
REDDIT_USER_AGENT = "your_user_agent"
```

> üîë **Note**: You can obtain Reddit API credentials by creating an app at [Reddit's App Preferences](https://www.reddit.com/prefs/apps)

### 4Ô∏è‚É£ Launch the Backend

```bash
python app.py
```

This will start the Flask server on http://localhost:5000.

### 5Ô∏è‚É£ Test the Application

```bash
python simple_test.py
```

This will:
- ‚ñ∂Ô∏è Start the Flask server in a new command window
- üß™ Run a test on the API endpoint
- üåê Open a simple HTML frontend in your browser for testing

## üìä Using the Application

1. üîç Enter a search term (e.g., "Python", "AI", "Web Development")
2. ‚úÖ Select platforms to search (Reddit, Hacker News, Quora)
3. üîò Click "Search" to retrieve and analyze data
4. üìà View sentiment analysis, top keywords, and sample results

## üèóÔ∏è Architecture

```mermaid
graph TD
    A[User Interface] --> B[Flask API Server]
    B --> C1[Reddit Scraper]
    B --> C2[Hacker News Scraper]
    B --> C3[Quora Scraper]
    C1 --> D[Data Aggregation]
    C2 --> D
    C3 --> D
    D --> E1[Sentiment Analysis]
    D --> E2[Keyword Extraction]
    E1 --> F[Results Processing]
    E2 --> F
    F --> G[Data Visualization]
    G --> A
```

### Data Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API
    participant Scrapers
    participant Analyzers
    
    User->>Frontend: Enter search term & platforms
    Frontend->>API: POST /api/search
    API->>Scrapers: Fetch data from platforms
    Scrapers-->>API: Return raw data
    API->>Analyzers: Process text & sentiment
    Analyzers-->>API: Return analysis results
    API-->>Frontend: Return processed data
    Frontend-->>User: Display visualizations & insights
```

### Component Structure

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                     ‚îÇ
‚îÇ                    User Interface                   ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                     ‚îÇ
‚îÇ                    Flask API Server                 ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ                     ‚îÇ                        ‚îÇ
   ‚ñº                     ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Scrapers ‚îÇ       ‚îÇ  Analyzers  ‚îÇ          ‚îÇ Visualizer‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ   ‚îÇ                  ‚îÇ                       ‚îÇ
   ‚îÇ   ‚îÇ                  ‚ñº                       ‚îÇ
   ‚îÇ   ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
   ‚îÇ   ‚îÇ          ‚îÇ  Sentiment  ‚îÇ                 ‚îÇ
   ‚îÇ   ‚îÇ          ‚îÇ  Analysis   ‚îÇ                 ‚îÇ
   ‚îÇ   ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
   ‚îÇ   ‚îÇ                 ‚îÇ                        ‚îÇ
   ‚îÇ   ‚îÇ                 ‚ñº                        ‚îÇ
   ‚îÇ   ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
   ‚îÇ   ‚îÇ          ‚îÇ   Keyword   ‚îÇ                 ‚îÇ
   ‚îÇ   ‚îÇ          ‚îÇ  Extraction ‚îÇ                 ‚îÇ
   ‚îÇ   ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
   ‚îÇ   ‚îÇ                                          ‚îÇ
   ‚ñº   ‚ñº                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                     ‚îÇ
‚îÇ                     Data Storage                    ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üé® UI Design

The Market Research Bot features a modern Bento UI design that provides:

- **Card-Based Layout**: Clean, organized information display using a grid system
- **Data Visualization**: Interactive sentiment bars and keyword clouds
- **Platform-Specific Insights**: Dedicated sections for each platform's analysis
- **Responsive Design**: Adapts to different screen sizes for optimal viewing
- **Visual Hierarchy**: Clear organization of information with intuitive navigation

### UI Components

| Component | Description |
|-----------|-------------|
| Search Panel | Allows users to input search terms and select platforms |
| Sentiment Dashboard | Displays overall sentiment analysis with color-coded indicators |
| Platform Breakdown | Shows sentiment distribution across different platforms |
| Keyword Cloud | Visual representation of trending topics sized by frequency |
| Results List | Displays sample discussions with sentiment indicators |
| Insights Panel | AI-generated summary of key findings and trends |

## üì¶ Project Structure

```
market-research-bot/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ scrapers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ reddit_scraper.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ hackernews_scraper.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ quora_scraper.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ analyzers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sentiment_analyzer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ keyword_extractor.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ visualizer.py
‚îÇ
‚îú‚îÄ‚îÄ üìÑ app.py              # Flask API server
‚îú‚îÄ‚îÄ üìÑ main.py             # Command-line interface
‚îú‚îÄ‚îÄ üìÑ test_api.py         # API endpoint tests
‚îú‚îÄ‚îÄ üìÑ simple_test.py      # Combined backend/frontend test
‚îú‚îÄ‚îÄ üìÑ test_frontend.html  # Simple HTML frontend for testing
‚îú‚îÄ‚îÄ üìÑ requirements.txt
‚îî‚îÄ‚îÄ üìÑ README.md
```

## üéØ Use Cases

Perfect for:

- üíª **Hackathon Teams** - Quickly validate ideas and understand market needs
- üöÄ **Indie Hackers** - Research product-market fit before building
- üè¢ **Startup Founders** - Track sentiment about your product or competitors
- üßë‚Äçüíª **Solo Developers** - Understand user pain points without endless forum reading

## üìù Future Improvements

- üê¶ Add more data sources (Twitter, Product Hunt, etc.)
- üß† Implement more advanced sentiment analysis models
- üìä Create a sophisticated frontend with interactive data visualizations
- üîê Add user authentication and saved searches
- ‚ö° Implement caching to improve performance

## üìú License

This project is licensed under the MIT License - see the LICENSE file for details.

## üë• Contributors

- BroCode
  ->Aastha Sawant
  ->Anant Srivastava
  ->Vivek Khandelwal

---

<div align="center">
  <p>Made with ‚ù§Ô∏è for the Hackathon</p>
</div>
